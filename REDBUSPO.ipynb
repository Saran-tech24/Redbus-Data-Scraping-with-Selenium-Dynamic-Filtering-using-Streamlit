{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 30)  # Increased timeout\n",
    "\n",
    "driver.get('https://www.redbus.in/online-booking/ksrtc-kerala/?utm_source=rtchometile')\n",
    "\n",
    "#Define a list to store all the route data\n",
    "Kerala_Route = []\n",
    "\n",
    "def scrape_page():\n",
    "    # Locate elements  (container)\n",
    "    routescontainer = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"route_link\")))\n",
    "\n",
    "    # Loop through each route to extract details\n",
    "    for route in routescontainer:\n",
    "        try:\n",
    "            routename= route.find_element(By.CLASS_NAME,'route').text\n",
    "            routelink= route.find_element(By.CLASS_NAME,'route').get_attribute('href')\n",
    "            #Then  Append extracted data to list\n",
    "            Kerala_Route.append({'routename':routename,'routelink':routelink})\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "# Scrape data from the first 5 pages\n",
    "for page_number in range(1, 3):\n",
    "    scrape_page()\n",
    "    if page_number < 2:  # Don't try to click next on the last page\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "\n",
    "            # Ensure the next page button is in view\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(1)  # Wait for a bit after scrolling\n",
    " \n",
    "\n",
    "            # Click the next page button\n",
    "            next_page_button.click()\n",
    "\n",
    "            # Wait for the page number to update to the next page\n",
    "            wait.until(EC.text_to_be_present_in_element(\n",
    "                (By.XPATH, '//div[contains(@class, \"DC_117_pageTabs DC_117_pageActive\")]'), str(page_number + 1)))\n",
    "\n",
    "            # Wait for a short duration to ensure the next page loads completely\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_KERALA_ROUTE = pd.DataFrame(Kerala_Route)\n",
    "df_KERALA_ROUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrive the bus details\n",
    "driver_KE = webdriver.Chrome()\n",
    "Bus_names_KE = []\n",
    "Bus_types_KE = []\n",
    "Start_Time_KE = []\n",
    "End_Time_KE = []\n",
    "Ratings_KE = []\n",
    "Total_Duration_KE = []\n",
    "Prices_KE = []\n",
    "Seats_Available_KE = []\n",
    "Route_names = []\n",
    "Route_links = []\n",
    "\n",
    "for i,r in df_KERALA_ROUTE.iterrows():\n",
    "    link=r[\"routelink\"]\n",
    "    routes=r[\"routename\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver_KE.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver_KE.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # click elements to views bus\n",
    "    try:\n",
    "        clicks = driver_KE.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "        clicks.click()\n",
    "    except:\n",
    "        continue  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    last_height = driver_KE.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver_KE.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Wait to load the page\n",
    "        new_height = driver_KE.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver_KE.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver_KE.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver_KE.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver_KE.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver_KE.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver_KE.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver_KE.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver_KE.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_KE.append(bus.text)\n",
    "        Route_links.append(link)\n",
    "        Route_names.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_KE.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_KE.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_KE.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_KE.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_KE.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_KE.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_KE.append(seats_elem.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERALA_DATA = {\n",
    "    'Bus_name': Bus_names_KE,\n",
    "    'Bus_type': Bus_types_KE,\n",
    "    'Start_time': Start_Time_KE,\n",
    "    'End_time': End_Time_KE,\n",
    "    'Total_duration': Total_Duration_KE,\n",
    "    'Price': Prices_KE,\n",
    "    \"Seats_Available\":Seats_Available_KE,\n",
    "    \"Ratings\":Ratings_KE,\n",
    "    'Route_link': Route_links,\n",
    "    'Route_name': Route_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERALA_DATA_1 = pd.DataFrame(KERALA_DATA)\n",
    "KERALA_DATA_1.to_csv(\"C:/Users/Admin/Desktop/REDBUS/ALLBUS/KE_BUS1.CSV\",index=False)\n",
    "KERALA_DATA_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 30)  # Increased timeout\n",
    "\n",
    "driver.get('https://www.redbus.in/online-booking/apsrtc/?utm_source=rtchometile')\n",
    "\n",
    "#Define a list to store all the route data\n",
    "AP_Route = []\n",
    "\n",
    "def scrape_page():\n",
    "    # Locate elements  (container)\n",
    "    routescontainer = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"route_link\")))\n",
    "\n",
    "    # Loop through each route to extract details\n",
    "    for route in routescontainer:\n",
    "        try:\n",
    "            routename= route.find_element(By.CLASS_NAME,'route').text\n",
    "            routelink= route.find_element(By.CLASS_NAME,'route').get_attribute('href')\n",
    "            #Then  Append extracted data to list\n",
    "            AP_Route.append({'routename':routename,'routelink':routelink})\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "# Scrape data from the first 5 pages\n",
    "for page_number in range(1, 6):\n",
    "    scrape_page()\n",
    "    if page_number < 5:  # Don't try to click next on the last page\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "\n",
    "            # Ensure the next page button is in view\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(1)  # Wait for a bit after scrolling\n",
    " \n",
    "\n",
    "            # Click the next page button\n",
    "            next_page_button.click()\n",
    "\n",
    "            # Wait for the page number to update to the next page\n",
    "            wait.until(EC.text_to_be_present_in_element(\n",
    "                (By.XPATH, '//div[contains(@class, \"DC_117_pageTabs DC_117_pageActive\")]'), str(page_number + 1)))\n",
    "\n",
    "            # Wait for a short duration to ensure the next page loads completely\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AP_ROUTE = pd.DataFrame(AP_Route)\n",
    "df_AP_ROUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrive the bus details\n",
    "driver_AP = webdriver.Chrome()\n",
    "Bus_names_AP = []\n",
    "Bus_types_AP = []\n",
    "Start_Time_AP = []\n",
    "End_Time_AP = []\n",
    "Ratings_AP = []\n",
    "Total_Duration_AP = []\n",
    "Prices_AP = []\n",
    "Seats_Available_AP = []\n",
    "Route_names = []\n",
    "Route_links = []\n",
    "\n",
    "for i,r in df_AP_ROUTE.iterrows():\n",
    "    link=r[\"routelink\"]\n",
    "    routes=r[\"routename\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver_AP.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver_AP.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # click elements to views bus\n",
    "    try:\n",
    "        clicks = driver_AP.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "        clicks.click()\n",
    "    except:\n",
    "        continue  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    last_height = driver_AP.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver_AP.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Wait to load the page\n",
    "        new_height = driver_AP.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver_AP.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver_AP.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver_AP.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver_AP.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver_AP.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver_AP.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver_AP.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver_AP.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_AP.append(bus.text)\n",
    "        Route_links.append(link)\n",
    "        Route_names.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_AP.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_AP.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_AP.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_AP.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_AP.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_AP.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_AP.append(seats_elem.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AP_DATA = {\n",
    "    'Bus_name': Bus_names_AP,\n",
    "    'Bus_type': Bus_types_AP,\n",
    "    'Start_time': Start_Time_AP,\n",
    "    'End_time': End_Time_AP,\n",
    "    'Total_duration': Total_Duration_AP,\n",
    "    'Price': Prices_AP,\n",
    "    \"Seats_Available\":Seats_Available_AP,\n",
    "    \"Ratings\":Ratings_AP,\n",
    "    'Route_link': Route_links,\n",
    "    'Route_name': Route_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AP_DATA_1 = pd.DataFrame(AP_DATA)\n",
    "AP_DATA_1.to_csv(\"C:/Users/Admin/Desktop/REDBUS/ALLBUS/AP_BUS1.CSV\",index=False)\n",
    "AP_DATA_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 30)  # Increased timeout\n",
    "\n",
    "driver.get('https://www.redbus.in/online-booking/tsrtc/?utm_source=rtchometile')\n",
    "\n",
    "#Define a list to store all the route data\n",
    "TS_Route = []\n",
    "\n",
    "def scrape_page():\n",
    "    # Locate elements  (container)\n",
    "    routescontainer = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"route_link\")))\n",
    "\n",
    "    # Loop through each route to extract details\n",
    "    for route in routescontainer:\n",
    "        try:\n",
    "            routename= route.find_element(By.CLASS_NAME,'route').text\n",
    "            routelink= route.find_element(By.CLASS_NAME,'route').get_attribute('href')\n",
    "            #Then  Append extracted data to list\n",
    "            TS_Route.append({'routename':routename,'routelink':routelink})\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "# Scrape data from the first 5 pages\n",
    "for page_number in range(1,4):\n",
    "    scrape_page()\n",
    "    if page_number < 3:  # Don't try to click next on the last page\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "\n",
    "            # Ensure the next page button is in view\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(1)  # Wait for a bit after scrolling\n",
    " \n",
    "\n",
    "            # Click the next page button\n",
    "            next_page_button.click()\n",
    "\n",
    "            # Wait for the page number to update to the next page\n",
    "            wait.until(EC.text_to_be_present_in_element(\n",
    "                (By.XPATH, '//div[contains(@class, \"DC_117_pageTabs DC_117_pageActive\")]'), str(page_number + 1)))\n",
    "\n",
    "            # Wait for a short duration to ensure the next page loads completely\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TS_ROUTE = pd.DataFrame(TS_Route)\n",
    "df_TS_ROUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrive the bus details\n",
    "driver_TS = webdriver.Chrome()\n",
    "Bus_names_TS = []\n",
    "Bus_types_TS = []\n",
    "Start_Time_TS = []\n",
    "End_Time_TS = []\n",
    "Ratings_TS = []\n",
    "Total_Duration_TS = []\n",
    "Prices_TS = []\n",
    "Seats_Available_TS = []\n",
    "Route_names = []\n",
    "Route_links = []\n",
    "\n",
    "for i,r in df_TS_ROUTE.iterrows():\n",
    "    link=r[\"routelink\"]\n",
    "    routes=r[\"routename\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver_TS.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver_TS.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # click elements to views bus\n",
    "    try:\n",
    "        clicks = driver_TS.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "        clicks.click()\n",
    "    except:\n",
    "        continue  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    last_height = driver_TS.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver_TS.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Wait to load the page\n",
    "        new_height = driver_TS.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver_TS.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver_TS.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver_TS.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver_TS.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver_TS.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver_TS.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver_TS.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver_TS.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_TS.append(bus.text)\n",
    "        Route_links.append(link)\n",
    "        Route_names.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_TS.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_TS.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_TS.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_TS.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_TS.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_TS.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_TS.append(seats_elem.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_DATA = {\n",
    "    'Bus_name': Bus_names_TS,\n",
    "    'Bus_type': Bus_types_TS,\n",
    "    'Start_time': Start_Time_TS,\n",
    "    'End_time': End_Time_TS,\n",
    "    'Total_duration': Total_Duration_TS,\n",
    "    'Price': Prices_TS,\n",
    "    \"Seats_Available\":Seats_Available_TS,\n",
    "    \"Ratings\":Ratings_TS,\n",
    "    'Route_link': Route_links,\n",
    "    'Route_name': Route_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_DATA_1 = pd.DataFrame(TS_DATA)\n",
    "TS_DATA_1.to_csv(\"C:/Users/Admin/Desktop/REDBUS/ALLBUS/TS_BUS1.CSV\",index=False)\n",
    "TS_DATA_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 30)  # Increased timeout\n",
    "\n",
    "driver.get('https://www.redbus.in/online-booking/rsrtc/?utm_source=rtchometile')\n",
    "\n",
    "#Define a list to store all the route data\n",
    "RS_Route = []\n",
    "\n",
    "def scrape_page():\n",
    "    # Locate elements  (container)\n",
    "    routescontainer = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"route_link\")))\n",
    "\n",
    "    # Loop through each route to extract details\n",
    "    for route in routescontainer:\n",
    "        try:\n",
    "            routename= route.find_element(By.CLASS_NAME,'route').text\n",
    "            routelink= route.find_element(By.CLASS_NAME,'route').get_attribute('href')\n",
    "            #Then  Append extracted data to list\n",
    "            RS_Route.append({'routename':routename,'routelink':routelink})\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "# Scrape data from the first 5 pages\n",
    "for page_number in range(1,4):\n",
    "    scrape_page()\n",
    "    if page_number < 3:  # Don't try to click next on the last page\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "\n",
    "            # Ensure the next page button is in view\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(1)  # Wait for a bit after scrolling\n",
    " \n",
    "\n",
    "            # Click the next page button\n",
    "            next_page_button.click()\n",
    "\n",
    "            # Wait for the page number to update to the next page\n",
    "            wait.until(EC.text_to_be_present_in_element(\n",
    "                (By.XPATH, '//div[contains(@class, \"DC_117_pageTabs DC_117_pageActive\")]'), str(page_number + 1)))\n",
    "\n",
    "            # Wait for a short duration to ensure the next page loads completely\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RS_ROUTE = pd.DataFrame(RS_Route)\n",
    "df_RS_ROUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrive the bus details\n",
    "driver_RS = webdriver.Chrome()\n",
    "Bus_names_RS = []\n",
    "Bus_types_RS = []\n",
    "Start_Time_RS = []\n",
    "End_Time_RS = []\n",
    "Ratings_RS = []\n",
    "Total_Duration_RS = []\n",
    "Prices_RS = []\n",
    "Seats_Available_RS = []\n",
    "Route_names = []\n",
    "Route_links = []\n",
    "\n",
    "for i,r in df_RS_ROUTE.iterrows():\n",
    "    link=r[\"routelink\"]\n",
    "    routes=r[\"routename\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver_RS.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver_RS.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # click elements to views bus\n",
    "    try:\n",
    "        clicks = driver_RS.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "        clicks.click()\n",
    "    except:\n",
    "        continue  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    last_height = driver_RS.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver_RS.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Wait to load the page\n",
    "        new_height = driver_RS.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver_RS.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver_RS.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver_RS.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver_RS.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver_RS.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver_RS.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver_RS.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver_RS.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_RS.append(bus.text)\n",
    "        Route_links.append(link)\n",
    "        Route_names.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_RS.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_RS.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_RS.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_RS.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_RS.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_RS.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_RS.append(seats_elem.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RS_DATA = {\n",
    "    'Bus_name': Bus_names_RS,\n",
    "    'Bus_type': Bus_types_RS,\n",
    "    'Start_time': Start_Time_RS,\n",
    "    'End_time': End_Time_RS,\n",
    "    'Total_duration': Total_Duration_RS,\n",
    "    'Price': Prices_RS,\n",
    "    \"Seats_Available\":Seats_Available_RS,\n",
    "    \"Ratings\":Ratings_RS,\n",
    "    'Route_link': Route_links,\n",
    "    'Route_name': Route_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RS_DATA_1 = pd.DataFrame(RS_DATA)\n",
    "RS_DATA_1.to_csv(\"C:/Users/Admin/Desktop/REDBUS/ALLBUS/RS_BUS1.CSV\",index=False)\n",
    "RS_DATA_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 30)  # Increased timeout\n",
    "\n",
    "driver.get('https://www.redbus.in/online-booking/south-bengal-state-transport-corporation-sbstc/?utm_source=rtchometile')\n",
    "\n",
    "#Define a list to store all the route data\n",
    "SB_Route = []\n",
    "\n",
    "def scrape_page():\n",
    "    # Locate elements  (container)\n",
    "    routescontainer = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"route_link\")))\n",
    "\n",
    "    # Loop through each route to extract details\n",
    "    for route in routescontainer:\n",
    "        try:\n",
    "            routename= route.find_element(By.CLASS_NAME,'route').text\n",
    "            routelink= route.find_element(By.CLASS_NAME,'route').get_attribute('href')\n",
    "            #Then  Append extracted data to list\n",
    "            SB_Route.append({'routename':routename,'routelink':routelink})\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "# Scrape data from the first 5 pages\n",
    "for page_number in range(1,6):\n",
    "    scrape_page()\n",
    "    if page_number < 5:  # Don't try to click next on the last page\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "\n",
    "            # Ensure the next page button is in view\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(1)  # Wait for a bit after scrolling\n",
    " \n",
    "\n",
    "            # Click the next page button\n",
    "            next_page_button.click()\n",
    "\n",
    "            # Wait for the page number to update to the next page\n",
    "            wait.until(EC.text_to_be_present_in_element(\n",
    "                (By.XPATH, '//div[contains(@class, \"DC_117_pageTabs DC_117_pageActive\")]'), str(page_number + 1)))\n",
    "\n",
    "            # Wait for a short duration to ensure the next page loads completely\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SB_ROUTE = pd.DataFrame(SB_Route)\n",
    "df_SB_ROUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrive the bus details\n",
    "driver_SB = webdriver.Chrome()\n",
    "Bus_names_SB = []\n",
    "Bus_types_SB = []\n",
    "Start_Time_SB = []\n",
    "End_Time_SB = []\n",
    "Ratings_SB = []\n",
    "Total_Duration_SB = []\n",
    "Prices_SB = []\n",
    "Seats_Available_SB = []\n",
    "Route_names = []\n",
    "Route_links = []\n",
    "\n",
    "for i,r in df_SB_ROUTE.iterrows():\n",
    "    link=r[\"routelink\"]\n",
    "    routes=r[\"routename\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver_SB.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver_SB.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # click elements to views bus\n",
    "    try:\n",
    "        clicks = driver_SB.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "        clicks.click()\n",
    "    except:\n",
    "        continue  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    last_height = driver_SB.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver_SB.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Wait to load the page\n",
    "        new_height = driver_SB.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver_SB.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver_SB.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver_SB.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver_SB.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver_SB.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver_SB.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver_SB.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver_SB.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_SB.append(bus.text)\n",
    "        Route_links.append(link)\n",
    "        Route_names.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_SB.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_SB.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_SB.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_SB.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_SB.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_SB.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_SB.append(seats_elem.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SB_DATA = {\n",
    "    'Bus_name': Bus_names_SB,\n",
    "    'Bus_type': Bus_types_SB,\n",
    "    'Start_time': Start_Time_SB,\n",
    "    'End_time': End_Time_SB,\n",
    "    'Total_duration': Total_Duration_SB,\n",
    "    'Price': Prices_SB,\n",
    "    \"Seats_Available\":Seats_Available_SB,\n",
    "    \"Ratings\":Ratings_SB,\n",
    "    'Route_link': Route_links,\n",
    "    'Route_name': Route_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SB_DATA_1 = pd.DataFrame(SB_DATA)\n",
    "SB_DATA_1.to_csv(\"C:/Users/Admin/Desktop/REDBUS/ALLBUS/SB_BUS1.CSV\",index=False)\n",
    "SB_DATA_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 30)  # Increased timeout\n",
    "\n",
    "driver.get('https://www.redbus.in/online-booking/astc/?utm_source=rtchometile')\n",
    "\n",
    "#Define a list to store all the route data\n",
    "AS_Route = []\n",
    "\n",
    "def scrape_page():\n",
    "    # Locate elements  (container)\n",
    "    routescontainer = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"route_link\")))\n",
    "\n",
    "    # Loop through each route to extract details\n",
    "    for route in routescontainer:\n",
    "        try:\n",
    "            routename= route.find_element(By.CLASS_NAME,'route').text\n",
    "            routelink= route.find_element(By.CLASS_NAME,'route').get_attribute('href')\n",
    "            #Then  Append extracted data to list\n",
    "            AS_Route.append({'routename':routename,'routelink':routelink})\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "# Scrape data from the first 5 pages\n",
    "for page_number in range(1, 6):\n",
    "    scrape_page()\n",
    "    if page_number < 5:  # Don't try to click next on the last page\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "\n",
    "            # Ensure the next page button is in view\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(1)  # Wait for a bit after scrolling\n",
    " \n",
    "\n",
    "            # Click the next page button\n",
    "            next_page_button.click()\n",
    "\n",
    "            # Wait for the page number to update to the next page\n",
    "            wait.until(EC.text_to_be_present_in_element(\n",
    "                (By.XPATH, '//div[contains(@class, \"DC_117_pageTabs DC_117_pageActive\")]'), str(page_number + 1)))\n",
    "\n",
    "            # Wait for a short duration to ensure the next page loads completely\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AS_ROUTE = pd.DataFrame(AS_Route)\n",
    "df_AS_ROUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrive the bus details\n",
    "driver_AS = webdriver.Chrome()\n",
    "Bus_names_AS = []\n",
    "Bus_types_AS = []\n",
    "Start_Time_AS = []\n",
    "End_Time_AS = []\n",
    "Ratings_AS = []\n",
    "Total_Duration_AS = []\n",
    "Prices_AS = []\n",
    "Seats_Available_AS = []\n",
    "Route_names = []\n",
    "Route_links = []\n",
    "\n",
    "for i,r in df_AS_ROUTE.iterrows():\n",
    "    link=r[\"routelink\"]\n",
    "    routes=r[\"routename\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver_AS.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver_AS.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # click elements to views bus\n",
    "    try:\n",
    "        clicks = driver_AS.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "        clicks.click()\n",
    "    except:\n",
    "        continue  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    last_height = driver_AS.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver_AS.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Wait to load the page\n",
    "        new_height = driver_AS.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver_AS.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver_AS.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver_AS.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver_AS.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver_AS.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver_AS.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver_AS.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver_AS.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_AS.append(bus.text)\n",
    "        Route_links.append(link)\n",
    "        Route_names.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_AS.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_AS.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_AS.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_AS.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_AS.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_AS.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_AS.append(seats_elem.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_DATA = {\n",
    "    'Bus_name': Bus_names_AS,\n",
    "    'Bus_type': Bus_types_AS,\n",
    "    'Start_time': Start_Time_AS,\n",
    "    'End_time': End_Time_AS,\n",
    "    'Total_duration': Total_Duration_AS,\n",
    "    'Price': Prices_AS,\n",
    "    \"Seats_Available\":Seats_Available_AS,\n",
    "    \"Ratings\":Ratings_AS,\n",
    "    'Route_link': Route_links,\n",
    "    'Route_name': Route_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_DATA_1 = pd.DataFrame(AS_DATA)\n",
    "AS_DATA_1.to_csv(\"C:/Users/Admin/Desktop/REDBUS/ALLBUS/AS_BUS1.CSV\",index=False)\n",
    "AS_DATA_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 30)  # Increased timeout\n",
    "\n",
    "driver.get('https://www.redbus.in/online-booking/uttar-pradesh-state-road-transport-corporation-upsrtc/?utm_source=rtchometile')\n",
    "\n",
    "#Define a list to store all the route data\n",
    "UP_Route = []\n",
    "\n",
    "def scrape_page():\n",
    "    # Locate elements  (container)\n",
    "    routescontainer = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"route_link\")))\n",
    "\n",
    "    # Loop through each route to extract details\n",
    "    for route in routescontainer:\n",
    "        try:\n",
    "            routename= route.find_element(By.CLASS_NAME,'route').text\n",
    "            routelink= route.find_element(By.CLASS_NAME,'route').get_attribute('href')\n",
    "            #Then  Append extracted data to list\n",
    "            UP_Route.append({'routename':routename,'routelink':routelink})\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "# Scrape data from the first 5 pages\n",
    "for page_number in range(1, 6):\n",
    "    scrape_page()\n",
    "    if page_number < 5:  # Don't try to click next on the last page\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "\n",
    "            # Ensure the next page button is in view\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(1)  # Wait for a bit after scrolling\n",
    " \n",
    "\n",
    "            # Click the next page button\n",
    "            next_page_button.click()\n",
    "\n",
    "            # Wait for the page number to update to the next page\n",
    "            wait.until(EC.text_to_be_present_in_element(\n",
    "                (By.XPATH, '//div[contains(@class, \"DC_117_pageTabs DC_117_pageActive\")]'), str(page_number + 1)))\n",
    "\n",
    "            # Wait for a short duration to ensure the next page loads completely\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UP_ROUTE = pd.DataFrame(UP_Route)\n",
    "df_UP_ROUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrive the bus details\n",
    "driver_UP = webdriver.Chrome()\n",
    "Bus_names_UP = []\n",
    "Bus_types_UP = []\n",
    "Start_Time_UP = []\n",
    "End_Time_UP = []\n",
    "Ratings_UP = []\n",
    "Total_Duration_UP = []\n",
    "Prices_UP = []\n",
    "Seats_Available_UP = []\n",
    "Route_names = []\n",
    "Route_links = []\n",
    "\n",
    "for i,r in df_UP_ROUTE.iterrows():\n",
    "    link=r[\"routelink\"]\n",
    "    routes=r[\"routename\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver_UP.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver_UP.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # click elements to views bus\n",
    "    try:\n",
    "        clicks = driver_UP.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "        clicks.click()\n",
    "    except:\n",
    "        continue  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    last_height = driver_UP.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver_UP.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Wait to load the page\n",
    "        new_height = driver_UP.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver_UP.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver_UP.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver_UP.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver_UP.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver_UP.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver_UP.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver_UP.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver_UP.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_UP.append(bus.text)\n",
    "        Route_links.append(link)\n",
    "        Route_names.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_UP.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_UP.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_UP.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_UP.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_UP.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_UP.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_UP.append(seats_elem.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "UP_DATA = {\n",
    "    'Bus_name': Bus_names_UP,\n",
    "    'Bus_type': Bus_types_UP,\n",
    "    'Start_time': Start_Time_UP,\n",
    "    'End_time': End_Time_UP,\n",
    "    'Total_duration': Total_Duration_UP,\n",
    "    'Price': Prices_UP,\n",
    "    \"Seats_Available\":Seats_Available_UP,\n",
    "    \"Ratings\":Ratings_UP,\n",
    "    'Route_link': Route_links,\n",
    "    'Route_name': Route_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UP_DATA_1 = pd.DataFrame(UP_DATA)\n",
    "UP_DATA_1.to_csv(\"C:/Users/Admin/Desktop/REDBUS/ALLBUS/UP_BUS1.CSV\",index=False)\n",
    "UP_DATA_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 30)  # Increased timeout\n",
    "\n",
    "driver.get('https://www.redbus.in/online-booking/north-bengal-state-transport-corporation')\n",
    "\n",
    "#Define a list to store all the route data\n",
    "NB_Route = []\n",
    "\n",
    "def scrape_page():\n",
    "    # Locate elements  (container)\n",
    "    routescontainer = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"route_link\")))\n",
    "\n",
    "    # Loop through each route to extract details\n",
    "    for route in routescontainer:\n",
    "        try:\n",
    "            routename= route.find_element(By.CLASS_NAME,'route').text\n",
    "            routelink= route.find_element(By.CLASS_NAME,'route').get_attribute('href')\n",
    "            #Then  Append extracted data to list\n",
    "            NB_Route.append({'routename':routename,'routelink':routelink})\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "# Scrape data from the first 5 pages\n",
    "for page_number in range(1, 6):\n",
    "    scrape_page()\n",
    "    if page_number < 5:  # Don't try to click next on the last page\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "\n",
    "            # Ensure the next page button is in view\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(1)  # Wait for a bit after scrolling\n",
    " \n",
    "\n",
    "            # Click the next page button\n",
    "            next_page_button.click()\n",
    "\n",
    "            # Wait for the page number to update to the next page\n",
    "            wait.until(EC.text_to_be_present_in_element(\n",
    "                (By.XPATH, '//div[contains(@class, \"DC_117_pageTabs DC_117_pageActive\")]'), str(page_number + 1)))\n",
    "\n",
    "            # Wait for a short duration to ensure the next page loads completely\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NB_ROUTE = pd.DataFrame(NB_Route)\n",
    "df_NB_ROUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrive the bus details\n",
    "driver_NB = webdriver.Chrome()\n",
    "Bus_names_NB = []\n",
    "Bus_types_NB = []\n",
    "Start_Time_NB = []\n",
    "End_Time_NB = []\n",
    "Ratings_NB = []\n",
    "Total_Duration_NB = []\n",
    "Prices_NB = []\n",
    "Seats_Available_NB = []\n",
    "Route_names = []\n",
    "Route_links = []\n",
    "\n",
    "for i,r in df_NB_ROUTE.iterrows():\n",
    "    link=r[\"routelink\"]\n",
    "    routes=r[\"routename\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver_NB.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver_NB.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # click elements to views bus\n",
    "    try:\n",
    "        clicks = driver_NB.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "        clicks.click()\n",
    "    except:\n",
    "        continue  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    last_height = driver_NB.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver_NB.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Wait to load the page\n",
    "        new_height = driver_NB.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver_NB.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver_NB.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver_NB.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver_NB.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver_NB.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver_NB.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver_NB.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver_NB.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_NB.append(bus.text)\n",
    "        Route_links.append(link)\n",
    "        Route_names.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_NB.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_NB.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_NB.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_NB.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_NB.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_NB.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_NB.append(seats_elem.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_DATA = {\n",
    "    'Bus_name': Bus_names_NB,\n",
    "    'Bus_type': Bus_types_NB,\n",
    "    'Start_time': Start_Time_NB,\n",
    "    'End_time': End_Time_NB,\n",
    "    'Total_duration': Total_Duration_NB,\n",
    "    'Price': Prices_NB,\n",
    "    \"Seats_Available\":Seats_Available_NB,\n",
    "    \"Ratings\":Ratings_NB,\n",
    "    'Route_link': Route_links,\n",
    "    'Route_name': Route_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_DATA_1 = pd.DataFrame(NB_DATA)\n",
    "NB_DATA_1.to_csv(\"C:/Users/Admin/Desktop/REDBUS/ALLBUS/NB_BUS1.CSV\",index=False)\n",
    "NB_DATA_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 30)  # Increased timeout\n",
    "\n",
    "driver.get('https://www.redbus.in/online-booking/chandigarh-transport-undertaking-ctu')\n",
    "\n",
    "#Define a list to store all the route data\n",
    "CD_Route = []\n",
    "\n",
    "def scrape_page():\n",
    "    # Locate elements  (container)\n",
    "    routescontainer = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"route_link\")))\n",
    "\n",
    "    # Loop through each route to extract details\n",
    "    for route in routescontainer:\n",
    "        try:\n",
    "            routename= route.find_element(By.CLASS_NAME,'route').text\n",
    "            routelink= route.find_element(By.CLASS_NAME,'route').get_attribute('href')\n",
    "            #Then  Append extracted data to list\n",
    "            CD_Route.append({'routename':routename,'routelink':routelink})\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "# Scrape data from the first 5 pages\n",
    "for page_number in range(1, 6):\n",
    "    scrape_page()\n",
    "    if page_number < 5:  # Don't try to click next on the last page\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "\n",
    "            # Ensure the next page button is in view\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(1)  # Wait for a bit after scrolling\n",
    " \n",
    "\n",
    "            # Click the next page button\n",
    "            next_page_button.click()\n",
    "\n",
    "            # Wait for the page number to update to the next page\n",
    "            wait.until(EC.text_to_be_present_in_element(\n",
    "                (By.XPATH, '//div[contains(@class, \"DC_117_pageTabs DC_117_pageActive\")]'), str(page_number + 1)))\n",
    "\n",
    "            # Wait for a short duration to ensure the next page loads completely\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CD_ROUTE = pd.DataFrame(CD_Route)\n",
    "df_CD_ROUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrive the bus details\n",
    "driver_CD = webdriver.Chrome()\n",
    "Bus_names_CD = []\n",
    "Bus_types_CD = []\n",
    "Start_Time_CD = []\n",
    "End_Time_CD = []\n",
    "Ratings_CD = []\n",
    "Total_Duration_CD = []\n",
    "Prices_CD = []\n",
    "Seats_Available_CD = []\n",
    "Route_names = []\n",
    "Route_links = []\n",
    "\n",
    "for i,r in df_CD_ROUTE.iterrows():\n",
    "    link=r[\"routelink\"]\n",
    "    routes=r[\"routename\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver_CD.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver_CD.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # click elements to views bus\n",
    "    try:\n",
    "        clicks = driver_CD.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "        clicks.click()\n",
    "    except:\n",
    "        continue  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    last_height = driver_CD.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver_CD.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Wait to load the page\n",
    "        new_height = driver_CD.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver_CD.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver_CD.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver_CD.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver_CD.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver_CD.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver_CD.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver_CD.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver_CD.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_CD.append(bus.text)\n",
    "        Route_links.append(link)\n",
    "        Route_names.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_CD.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_CD.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_CD.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_CD.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_CD.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_CD.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_CD.append(seats_elem.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "CD_DATA = {\n",
    "    'Bus_name': Bus_names_CD,\n",
    "    'Bus_type': Bus_types_CD,\n",
    "    'Start_time': Start_Time_CD,\n",
    "    'End_time': End_Time_CD,\n",
    "    'Total_duration': Total_Duration_CD,\n",
    "    'Price': Prices_CD,\n",
    "    \"Seats_Available\":Seats_Available_CD,\n",
    "    \"Ratings\":Ratings_CD,\n",
    "    'Route_link': Route_links,\n",
    "    'Route_name': Route_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CD_DATA_1 = pd.DataFrame(CD_DATA)\n",
    "CD_DATA_1.to_csv(\"C:/Users/Admin/Desktop/REDBUS/ALLBUS/CD_BUS1.CSV\",index=False)\n",
    "CD_DATA_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 30)  # Increased timeout\n",
    "\n",
    "driver.get('https://www.redbus.in/online-booking/pepsu/?utm_source=rtchometile')\n",
    "\n",
    "#Define a list to store all the route data\n",
    "PUNJAB_Route = []\n",
    "\n",
    "def scrape_page():\n",
    "    # Locate elements  (container)\n",
    "    routescontainer = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"route_link\")))\n",
    "\n",
    "    # Loop through each route to extract details\n",
    "    for route in routescontainer:\n",
    "        try:\n",
    "            routename= route.find_element(By.CLASS_NAME,'route').text\n",
    "            routelink= route.find_element(By.CLASS_NAME,'route').get_attribute('href')\n",
    "            #Then  Append extracted data to list\n",
    "            PUNJAB_Route.append({'routename':routename,'routelink':routelink})\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "# Scrape data from the first 5 pages\n",
    "for page_number in range(1,4):\n",
    "    scrape_page()\n",
    "    if page_number < 3:  # Don't try to click next on the last page\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "\n",
    "            # Ensure the next page button is in view\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(1)  # Wait for a bit after scrolling\n",
    " \n",
    "\n",
    "            # Click the next page button\n",
    "            next_page_button.click()\n",
    "\n",
    "            # Wait for the page number to update to the next page\n",
    "            wait.until(EC.text_to_be_present_in_element(\n",
    "                (By.XPATH, '//div[contains(@class, \"DC_117_pageTabs DC_117_pageActive\")]'), str(page_number + 1)))\n",
    "\n",
    "            # Wait for a short duration to ensure the next page loads completely\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PUNJAB_ROUTE = pd.DataFrame(PUNJAB_Route)\n",
    "df_PUNJAB_ROUTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrive the bus details\n",
    "driver_PUNJAB = webdriver.Chrome()\n",
    "Bus_names_PUNJAB = []\n",
    "Bus_types_PUNJAB = []\n",
    "Start_Time_PUNJAB = []\n",
    "End_Time_PUNJAB = []\n",
    "Ratings_PUNJAB = []\n",
    "Total_Duration_PUNJAB = []\n",
    "Prices_PUNJAB = []\n",
    "Seats_Available_PUNJAB = []\n",
    "Route_names = []\n",
    "Route_links = []\n",
    "\n",
    "for i,r in df_PUNJAB_ROUTE.iterrows():\n",
    "    link=r[\"routelink\"]\n",
    "    routes=r[\"routename\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver_PUNJAB.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver_PUNJAB.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # click elements to views bus\n",
    "    try:\n",
    "        clicks = driver_PUNJAB.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "        clicks.click()\n",
    "    except:\n",
    "        continue  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    last_height = driver_PUNJAB.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver_PUNJAB.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Wait to load the page\n",
    "        new_height = driver_PUNJAB.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver_PUNJAB.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver_PUNJAB.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver_PUNJAB.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver_PUNJAB.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver_PUNJAB.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver_PUNJAB.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver_PUNJAB.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver_PUNJAB.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_PUNJAB.append(bus.text)\n",
    "        Route_links.append(link)\n",
    "        Route_names.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_PUNJAB.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_PUNJAB.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_PUNJAB.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_PUNJAB.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_PUNJAB.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_PUNJAB.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_PUNJAB.append(seats_elem.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNJAB_DATA = {\n",
    "    'Bus_name': Bus_names_PUNJAB,\n",
    "    'Bus_type': Bus_types_PUNJAB,\n",
    "    'Start_time': Start_Time_PUNJAB,\n",
    "    'End_time': End_Time_PUNJAB,\n",
    "    'Total_duration': Total_Duration_PUNJAB,\n",
    "    'Price': Prices_PUNJAB,\n",
    "    \"Seats_Available\":Seats_Available_PUNJAB,\n",
    "    \"Ratings\":Ratings_PUNJAB,\n",
    "    'Route_link': Route_links,\n",
    "    'Route_name': Route_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNJAB_DATA_1 = pd.DataFrame(PUNJAB_DATA)\n",
    "PUNJAB_DATA_1.to_csv(\"C:/Users/Admin/Desktop/REDBUS/ALLBUS/PUNJAB_BUS1.CSV\",index=False)\n",
    "PUNJAB_DATA_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
